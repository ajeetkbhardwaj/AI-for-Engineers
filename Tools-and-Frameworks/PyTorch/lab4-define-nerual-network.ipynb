{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bedc36c",
   "metadata": {},
   "source": [
    "torch and it's subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74081e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d611dc1",
   "metadata": {},
   "source": [
    "1. Define and Initialize a Convolutional Neural Network\n",
    "\n",
    "What is convolution ?\n",
    "A process that adds each element of an image with it's neighbors, weighted by kernel(smaller matrix). It help us to extract certain features from the input images like edge detection, sharpness, blurriness etc.\n",
    "\n",
    "What is Convolutional Neural Network(CNN) ?\n",
    "It's a collection of such convolution unit layers connected as networks for learning the features from the images i.e those parameters of kernels etc.\n",
    "\n",
    "In PyTorch, How to define a CNN model ?\n",
    "1. Initialization : __init__() function that inherits(reference) the `nn.Module`.\n",
    "2. Define CNN_model as a class and then add to fully connected convolution layers in our networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f8876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # 1. 2D convolutional layer : 1 input channel, 32 output convolutional features, 3x3 kernel\n",
    "        self.conv1 = nn.Conv2D(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # 2. 2D convolutional layer : 32 input channels, 64 output convolutional features, 3x3 kernel\n",
    "        self.conv2 = nn.Conv2D(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # 3. 2D convolutional layer : 64 input channels, 128 output convolutional features, 3x3 kernel\n",
    "        self.conv3 = nn.Conv2D(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        # 6. Dropout layer with 0.5 probability\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        # 3. Fully connected layer : 128*7*7 input features, 256 output features\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 256)\n",
    "        # 4. Fully connected layer : 256 input features, 10 output features (for 10 classes)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        # 1. Apply first convolutional layer, followed by ReLU activation and max pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # 2. Apply second convolutional layer, followed by ReLU activation and max pooling\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # 3. Apply third convolutional layer, followed by ReLU activation and dropout\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout1(x)\n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        # 4. Apply first fully connected layer, followed by ReLU activation and dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        # 5. Apply second fully connected layer (output layer)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
