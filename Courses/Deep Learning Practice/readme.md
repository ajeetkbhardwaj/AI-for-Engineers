# Deep Learning Practice 
**Objective**

1. Understand core concepts of Natural Language Processing (NLP) and Computer Vision (CV) using modern deep learning and Transformer-based architectures.
2. Gain practical skills in implementing and fine-tuning models with **Hugging Face Transformers**.
3. Explore multimodal learning â€” combining text, speech, and vision.
4. Learn to build end-to-end intelligent systems for real-world applications.

---

## Table of Contents

* [ ] **W1 : Introduction to Modern NLP and Hugging Face**

  * [ ] L1 : Overview of NLP pipeline and challenges
  * [ ] L2 : Hugging Face Hub, Datasets, and Transformers library

* [ ] **W2 : Tokenization**

  * [ ] L1 : Subword tokenization (BPE, WordPiece, SentencePiece)
  * [ ] L2 : Custom tokenizer training and vocabulary optimization

* [ ] **W3 : Fine-tuning Models for Downstream Tasks**

  * [ ] L1 : Text classification, NER, and QA tasks
  * [ ] L2 : Evaluation metrics and error analysis

* [ ] **W4 : Continual Pre-training and Instruction Tuning**

  * [ ] L1 : Domain adaptation and continued pretraining
  * [ ] L2 : Instruction tuning for task generalization

* [ ] **W5 : Spoken Language Identification**

  * [ ] L1 : Basics of speech processing
  * [ ] L2 : Language detection using audio embeddings

* [ ] **W6 : Speaker Diarisation**

  * [ ] L1 : Voice activity detection and segmentation
  * [ ] L2 : Speaker embedding extraction (x-vectors, ECAPA-TDNN)

* [ ] **W7 : Speech to Text and Text to Speech Synthesis**

  * [ ] L1 : ASR using Wav2Vec2 / Whisper
  * [ ] L2 : TTS using Tacotron and FastSpeech models

* [ ] **W8 : Wake Word Detection and Personalization**

  * [ ] L1 : Keyword spotting algorithms
  * [ ] L2 : Personalized wake word adaptation

* [ ] **W9 : Image Classification**

  * [ ] L1 : CNNs vs Vision Transformers (ViT)
  * [ ] L2 : Transfer learning with pre-trained models

* [ ] **W10 : Object Detection**

  * [ ] L1 : Bounding box prediction (YOLO, DETR)
  * [ ] L2 : Evaluation (mAP, IoU) and deployment

* [ ] **W11 : Image-based Depth Estimation**

  * [ ] L1 : Monocular depth estimation with Transformers
  * [ ] L2 : Multi-view and stereo depth learning

* [ ] **W12 : Image Super-Resolution**

  * [ ] L1 : SRGAN, ESRGAN, and diffusion-based approaches
  * [ ] L2 : Evaluation and real-world enhancement applications

---

### Week-1 :
1. https://huggingface.co/datasets/stanfordnlp/imdb
2. 